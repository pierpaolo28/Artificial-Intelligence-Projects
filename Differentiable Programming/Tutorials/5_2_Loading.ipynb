{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "8bj1l5TvzDgs",
    "nbgrader": {
     "checksum": "2e433cbdd5b1bc32ffca46551a708e45",
     "grade": false,
     "grade_id": "cell-c290b2da5fe2edf3",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Part 2: Loading a saved model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "xDx8hjvYzDgv",
    "nbgrader": {
     "checksum": "f548e96caa143d15f7b0ec97bd4e149f",
     "grade": false,
     "grade_id": "cell-ba8019f876600bdf",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "__Before starting, we recommend you enable GPU acceleration if you're running on Colab. You'll also need to upload the weights you downloaded previously using the following block and using the upload button to upload your bettercnn.weights file:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "executionInfo": {
     "elapsed": 33831,
     "status": "ok",
     "timestamp": 1585474267505,
     "user": {
      "displayName": "Pier Paolo Ippolito",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjAj9U2nofERZJ9Sw2cUfGIXHe_5S_wb80SU9gr9A=s64",
      "userId": "11847293594480931962"
     },
     "user_tz": -60
    },
    "id": "gyLAmZhVzDgx",
    "nbgrader": {
     "checksum": "c0d2caf75989226e03a8ded7438278a5",
     "grade": false,
     "grade_id": "cell-7baa302f182176c7",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "outputId": "b0ec4bfa-040a-4a74-cc60-d47e2839282c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchbearer\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/e9/4049a47dd2e5b6346a2c5d215b0c67dce814afbab1cd54ce024533c4834e/torchbearer-0.5.3-py3-none-any.whl (138kB)\n",
      "\u001b[K     |████████████████████████████████| 143kB 5.1MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchbearer) (1.18.2)\n",
      "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from torchbearer) (1.4.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchbearer) (4.38.0)\n",
      "Installing collected packages: torchbearer\n",
      "Successfully installed torchbearer-0.5.3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-faec388c-ca49-4bda-a33f-6582aa8ab238\" name=\"files[]\" multiple disabled />\n",
       "     <output id=\"result-faec388c-ca49-4bda-a33f-6582aa8ab238\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving bettercnn.weights to bettercnn.weights\n",
      "--2020-03-29 09:30:53--  http://comp6248.ecs.soton.ac.uk/labs/lab5/0.PNG\n",
      "Resolving comp6248.ecs.soton.ac.uk (comp6248.ecs.soton.ac.uk)... 185.199.110.153, 185.199.109.153, 185.199.108.153, ...\n",
      "Connecting to comp6248.ecs.soton.ac.uk (comp6248.ecs.soton.ac.uk)|185.199.110.153|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2514 (2.5K) [image/png]\n",
      "Saving to: ‘0.PNG’\n",
      "\n",
      "0.PNG               100%[===================>]   2.46K  --.-KB/s    in 0s      \n",
      "\n",
      "2020-03-29 09:30:54 (728 MB/s) - ‘0.PNG’ saved [2514/2514]\n",
      "\n",
      "--2020-03-29 09:30:55--  http://comp6248.ecs.soton.ac.uk/labs/lab5/1.PNG\n",
      "Resolving comp6248.ecs.soton.ac.uk (comp6248.ecs.soton.ac.uk)... 185.199.110.153, 185.199.109.153, 185.199.108.153, ...\n",
      "Connecting to comp6248.ecs.soton.ac.uk (comp6248.ecs.soton.ac.uk)|185.199.110.153|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2448 (2.4K) [image/png]\n",
      "Saving to: ‘1.PNG’\n",
      "\n",
      "1.PNG               100%[===================>]   2.39K  --.-KB/s    in 0s      \n",
      "\n",
      "2020-03-29 09:30:55 (521 MB/s) - ‘1.PNG’ saved [2448/2448]\n",
      "\n",
      "--2020-03-29 09:30:56--  http://comp6248.ecs.soton.ac.uk/labs/lab5/2.PNG\n",
      "Resolving comp6248.ecs.soton.ac.uk (comp6248.ecs.soton.ac.uk)... 185.199.110.153, 185.199.109.153, 185.199.108.153, ...\n",
      "Connecting to comp6248.ecs.soton.ac.uk (comp6248.ecs.soton.ac.uk)|185.199.110.153|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 156 [image/png]\n",
      "Saving to: ‘2.PNG’\n",
      "\n",
      "2.PNG               100%[===================>]     156  --.-KB/s    in 0s      \n",
      "\n",
      "2020-03-29 09:30:57 (33.5 MB/s) - ‘2.PNG’ saved [156/156]\n",
      "\n",
      "--2020-03-29 09:30:58--  http://comp6248.ecs.soton.ac.uk/labs/lab5/3.PNG\n",
      "Resolving comp6248.ecs.soton.ac.uk (comp6248.ecs.soton.ac.uk)... 185.199.110.153, 185.199.109.153, 185.199.108.153, ...\n",
      "Connecting to comp6248.ecs.soton.ac.uk (comp6248.ecs.soton.ac.uk)|185.199.110.153|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 229 [image/png]\n",
      "Saving to: ‘3.PNG’\n",
      "\n",
      "3.PNG               100%[===================>]     229  --.-KB/s    in 0s      \n",
      "\n",
      "2020-03-29 09:30:58 (72.8 MB/s) - ‘3.PNG’ saved [229/229]\n",
      "\n",
      "--2020-03-29 09:30:59--  http://comp6248.ecs.soton.ac.uk/labs/lab5/4.PNG\n",
      "Resolving comp6248.ecs.soton.ac.uk (comp6248.ecs.soton.ac.uk)... 185.199.110.153, 185.199.109.153, 185.199.108.153, ...\n",
      "Connecting to comp6248.ecs.soton.ac.uk (comp6248.ecs.soton.ac.uk)|185.199.110.153|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 175 [image/png]\n",
      "Saving to: ‘4.PNG’\n",
      "\n",
      "4.PNG               100%[===================>]     175  --.-KB/s    in 0s      \n",
      "\n",
      "2020-03-29 09:30:59 (38.3 MB/s) - ‘4.PNG’ saved [175/175]\n",
      "\n",
      "--2020-03-29 09:31:01--  http://comp6248.ecs.soton.ac.uk/labs/lab5/5.PNG\n",
      "Resolving comp6248.ecs.soton.ac.uk (comp6248.ecs.soton.ac.uk)... 185.199.110.153, 185.199.109.153, 185.199.108.153, ...\n",
      "Connecting to comp6248.ecs.soton.ac.uk (comp6248.ecs.soton.ac.uk)|185.199.110.153|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 155 [image/png]\n",
      "Saving to: ‘5.PNG’\n",
      "\n",
      "5.PNG               100%[===================>]     155  --.-KB/s    in 0s      \n",
      "\n",
      "2020-03-29 09:31:01 (39.5 MB/s) - ‘5.PNG’ saved [155/155]\n",
      "\n",
      "--2020-03-29 09:31:02--  http://comp6248.ecs.soton.ac.uk/labs/lab5/6.PNG\n",
      "Resolving comp6248.ecs.soton.ac.uk (comp6248.ecs.soton.ac.uk)... 185.199.110.153, 185.199.109.153, 185.199.108.153, ...\n",
      "Connecting to comp6248.ecs.soton.ac.uk (comp6248.ecs.soton.ac.uk)|185.199.110.153|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 274 [image/png]\n",
      "Saving to: ‘6.PNG’\n",
      "\n",
      "6.PNG               100%[===================>]     274  --.-KB/s    in 0s      \n",
      "\n",
      "2020-03-29 09:31:02 (50.3 MB/s) - ‘6.PNG’ saved [274/274]\n",
      "\n",
      "--2020-03-29 09:31:03--  http://comp6248.ecs.soton.ac.uk/labs/lab5/7.PNG\n",
      "Resolving comp6248.ecs.soton.ac.uk (comp6248.ecs.soton.ac.uk)... 185.199.110.153, 185.199.109.153, 185.199.108.153, ...\n",
      "Connecting to comp6248.ecs.soton.ac.uk (comp6248.ecs.soton.ac.uk)|185.199.110.153|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 157 [image/png]\n",
      "Saving to: ‘7.PNG’\n",
      "\n",
      "7.PNG               100%[===================>]     157  --.-KB/s    in 0s      \n",
      "\n",
      "2020-03-29 09:31:03 (50.7 MB/s) - ‘7.PNG’ saved [157/157]\n",
      "\n",
      "--2020-03-29 09:31:05--  http://comp6248.ecs.soton.ac.uk/labs/lab5/8.PNG\n",
      "Resolving comp6248.ecs.soton.ac.uk (comp6248.ecs.soton.ac.uk)... 185.199.110.153, 185.199.109.153, 185.199.108.153, ...\n",
      "Connecting to comp6248.ecs.soton.ac.uk (comp6248.ecs.soton.ac.uk)|185.199.110.153|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 246 [image/png]\n",
      "Saving to: ‘8.PNG’\n",
      "\n",
      "8.PNG               100%[===================>]     246  --.-KB/s    in 0s      \n",
      "\n",
      "2020-03-29 09:31:05 (60.9 MB/s) - ‘8.PNG’ saved [246/246]\n",
      "\n",
      "--2020-03-29 09:31:06--  http://comp6248.ecs.soton.ac.uk/labs/lab5/9.PNG\n",
      "Resolving comp6248.ecs.soton.ac.uk (comp6248.ecs.soton.ac.uk)... 185.199.110.153, 185.199.109.153, 185.199.108.153, ...\n",
      "Connecting to comp6248.ecs.soton.ac.uk (comp6248.ecs.soton.ac.uk)|185.199.110.153|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 261 [image/png]\n",
      "Saving to: ‘9.PNG’\n",
      "\n",
      "9.PNG               100%[===================>]     261  --.-KB/s    in 0s      \n",
      "\n",
      "2020-03-29 09:31:06 (64.4 MB/s) - ‘9.PNG’ saved [261/261]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Execute this code block to install dependencies when running on colab\n",
    "try:\n",
    "    import torch\n",
    "except:\n",
    "    from os.path import exists\n",
    "    from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
    "    platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
    "    cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
    "    accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
    "\n",
    "    !pip install -q http://download.pytorch.org/whl/{accelerator}/torch-1.0.0-{platform}-linux_x86_64.whl torchvision\n",
    "    \n",
    "try: \n",
    "    import torchbearer\n",
    "except:\n",
    "    !pip install torchbearer\n",
    "\n",
    "try:\n",
    "    from google.colab import files\n",
    "    uploaded = files.upload()\n",
    "except:\n",
    "    print(\"Not running on colab. Ignoring.\")\n",
    "\n",
    "!wget http://comp6248.ecs.soton.ac.uk/labs/lab5/0.PNG\n",
    "!wget http://comp6248.ecs.soton.ac.uk/labs/lab5/1.PNG\n",
    "!wget http://comp6248.ecs.soton.ac.uk/labs/lab5/2.PNG\n",
    "!wget http://comp6248.ecs.soton.ac.uk/labs/lab5/3.PNG\n",
    "!wget http://comp6248.ecs.soton.ac.uk/labs/lab5/4.PNG\n",
    "!wget http://comp6248.ecs.soton.ac.uk/labs/lab5/5.PNG\n",
    "!wget http://comp6248.ecs.soton.ac.uk/labs/lab5/6.PNG\n",
    "!wget http://comp6248.ecs.soton.ac.uk/labs/lab5/7.PNG\n",
    "!wget http://comp6248.ecs.soton.ac.uk/labs/lab5/8.PNG\n",
    "!wget http://comp6248.ecs.soton.ac.uk/labs/lab5/9.PNG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "sweSXTGlzDg1",
    "nbgrader": {
     "checksum": "ce20db2649381e63c13307bcd496ab41",
     "grade": false,
     "grade_id": "cell-05dc06c4f046cee9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Reading models and propagating input\n",
    "\n",
    "At this point, we know how to train a model and how to save the resultant weights. Let's assume we're in the business of building a real system for handwritten character recognition; we need to be able to read in a previously trained model and forward propagate an image from outside the MNIST dataset through it in order to generate a prediction. Let's build some code to do just that. Firstly we need to load the model we saved in the previous part of the lab; PyTorch doesn't save the model structure by default, so you'll need to copy-paste the `BetterCNN` `forward` method implementation from the previous workbook into the block below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "ZshtBOejzDg2",
    "nbgrader": {
     "checksum": "83517d0b5dd9912b14e753371891acda",
     "grade": false,
     "grade_id": "cell-25d7ce8447ab7c15",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# automatically reload external modules if they change\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch \n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "\n",
    "# Model Definition\n",
    "class BetterCNN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(BetterCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 30, (5, 5), padding=0)\n",
    "        self.conv2 = nn.Conv2d(30, 15, (3, 3), padding=0)\n",
    "        self.fc1 = nn.Linear(15 * 5**2, 128)\n",
    "        self.fc2 = nn.Linear(128, 50)\n",
    "        self.fc3 = nn.Linear(50, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = F.relu(out)\n",
    "        out = F.max_pool2d(out, (2,2))\n",
    "        out = self.conv2(out)\n",
    "        out = F.relu(out)\n",
    "        out = F.max_pool2d(out, (2,2))\n",
    "        out = F.dropout(out, 0.2, training=self.training)\n",
    "        out = out.view(out.shape[0], -1)\n",
    "        out = self.fc1(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.fc3(out)\n",
    "        return out\n",
    "\n",
    "# build the model and load state\n",
    "model = BetterCNN()\n",
    "model.load_state_dict(torch.load('bettercnn.weights'))\n",
    "\n",
    "# put model in eval mode\n",
    "model = model.eval() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "v2H2hLF6zDg5",
    "nbgrader": {
     "checksum": "97971f78e75437a324758a0adf66779f",
     "grade": false,
     "grade_id": "cell-05d9eb94a8c5425c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "We've provided a set of images you can try. Let's load the one corresponding to a '1', convert it to a tensor, and display it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "executionInfo": {
     "elapsed": 763,
     "status": "ok",
     "timestamp": 1585474349400,
     "user": {
      "displayName": "Pier Paolo Ippolito",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjAj9U2nofERZJ9Sw2cUfGIXHe_5S_wb80SU9gr9A=s64",
      "userId": "11847293594480931962"
     },
     "user_tz": -60
    },
    "id": "XQ7nFgmrzDg7",
    "nbgrader": {
     "checksum": "c711239daefae20c86dd0d9036bdfacd",
     "grade": false,
     "grade_id": "cell-4bd7da9513437358",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "outputId": "bb17cea3-5b51-4df5-9be1-ad7aec1b99e0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa1812de320>"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOTf8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import torchvision\n",
    "\n",
    "transform = torchvision.transforms.ToTensor()\n",
    "im = transform(Image.open(\"1.PNG\"))\n",
    "\n",
    "plt.imshow(im[0], cmap=plt.get_cmap('gray'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "TGStmrhTzDg_",
    "nbgrader": {
     "checksum": "56476fa5813e1c34650810d8eed151ef",
     "grade": false,
     "grade_id": "cell-6cf292098a212188",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Now we'll use the model to make a prediction. The model expects input to have a batch dimension, so we use `unsqueeze(0)` to prepend one to the image. Recall that the model outputs the logits of the classes; the index of the biggest one will tell us which class has been predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "executionInfo": {
     "elapsed": 811,
     "status": "ok",
     "timestamp": 1585474353557,
     "user": {
      "displayName": "Pier Paolo Ippolito",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjAj9U2nofERZJ9Sw2cUfGIXHe_5S_wb80SU9gr9A=s64",
      "userId": "11847293594480931962"
     },
     "user_tz": -60
    },
    "id": "ZDdKEP7uzDhA",
    "nbgrader": {
     "checksum": "ff7a048101ce27cbe780653cd8468eca",
     "grade": false,
     "grade_id": "cell-92042c8f7b09a26d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "outputId": "539b352b-b4ce-435c-f8be-d60ec04d2ef5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits: tensor([[-5.8414,  8.6691, -0.9427, -1.7397, -0.4396, -6.6390, -5.0226,  3.6033,\n",
      "          2.8477, -0.3051]])\n",
      "predicted class: 1\n"
     ]
    }
   ],
   "source": [
    "batch = im.unsqueeze(0)\n",
    "predictions = model(batch)\n",
    "\n",
    "print(\"logits:\", predictions.data)\n",
    "\n",
    "_, predicted_class = predictions.max(1)\n",
    "\n",
    "print(\"predicted class:\", predicted_class.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "JLbSp9VXzDhD",
    "nbgrader": {
     "checksum": "e83d2f7a42effd9370d399d819d592e3",
     "grade": false,
     "grade_id": "cell-dbe9d30ed68054cf",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "We've provided images `0.PNG` through to `9.PNG` for you to play with. Use the following code block to classify each image and print the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 721
    },
    "colab_type": "code",
    "deletable": false,
    "executionInfo": {
     "elapsed": 751,
     "status": "ok",
     "timestamp": 1585474356784,
     "user": {
      "displayName": "Pier Paolo Ippolito",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjAj9U2nofERZJ9Sw2cUfGIXHe_5S_wb80SU9gr9A=s64",
      "userId": "11847293594480931962"
     },
     "user_tz": -60
    },
    "id": "JnPrFTGGzDhE",
    "nbgrader": {
     "checksum": "2c942b974467a9a456a2e9e4389b6f7c",
     "grade": false,
     "grade_id": "cell-27a634204f34e601",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "outputId": "78d795ec-1181-48bb-b492-89af8829e6be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Number 0\n",
      "logits: tensor([[11.7492, -8.9682, -2.6139, -4.1404, -7.5197, -9.9763, -3.8231, -4.5429,\n",
      "         -5.7146,  2.9074]])\n",
      "predicted class: 0\n",
      "Image Number 1\n",
      "logits: tensor([[-5.8414,  8.6691, -0.9427, -1.7397, -0.4396, -6.6390, -5.0226,  3.6033,\n",
      "          2.8477, -0.3051]])\n",
      "predicted class: 1\n",
      "Image Number 2\n",
      "logits: tensor([[-0.4489,  1.8570, 12.3625,  0.7467, -4.5997, -8.4508, -8.7154,  4.5068,\n",
      "         -2.7444, -8.1101]])\n",
      "predicted class: 2\n",
      "Image Number 3\n",
      "logits: tensor([[-14.3880,   1.4825,   1.8314,  16.8374,  -7.3239,   0.0970, -16.3111,\n",
      "           1.3905,  -2.0066,  -4.8623]])\n",
      "predicted class: 3\n",
      "Image Number 4\n",
      "logits: tensor([[-10.0794,  -0.3632,  -1.6373,  -6.7488,  11.8770,  -4.2041,  -3.3925,\n",
      "          -1.0184,   2.5078,  -2.4928]])\n",
      "predicted class: 4\n",
      "Image Number 5\n",
      "logits: tensor([[-4.7780, -5.3403, -8.4630, -1.3299, -3.3032, 14.1803, -2.1697, -1.8791,\n",
      "          0.8421,  3.6171]])\n",
      "predicted class: 5\n",
      "Image Number 6\n",
      "logits: tensor([[-0.2125, -8.0712, -3.9533, -3.8144, -5.4138, 11.1535,  6.7416, -8.2025,\n",
      "          3.7785,  0.0993]])\n",
      "predicted class: 5\n",
      "Image Number 7\n",
      "logits: tensor([[ -9.6889,   0.8964,   4.8685,   5.8133,   3.0325,  -8.8586, -11.3796,\n",
      "          13.1051,  -5.1379,  -5.9326]])\n",
      "predicted class: 7\n",
      "Image Number 8\n",
      "logits: tensor([[-4.7828, -7.3154, -0.2719,  2.0764, -4.5620, -0.6567, -3.2821, -3.9693,\n",
      "         15.8818, -0.1102]])\n",
      "predicted class: 8\n",
      "Image Number 9\n",
      "logits: tensor([[ -9.1820,  -2.0155,   0.9196,  -0.0311,   6.2677,  -3.5219, -13.7378,\n",
      "           2.9247,   1.3028,   4.8483]])\n",
      "predicted class: 4\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,10):\n",
    "  print(\"Image Number \" + str(i))\n",
    "  im = transform(Image.open(str(i) + \".PNG\"))\n",
    "  batch = im.unsqueeze(0)\n",
    "  predictions = model(batch)\n",
    "  print(\"logits:\", predictions.data)\n",
    "  _, predicted_class = predictions.max(1)\n",
    "  print(\"predicted class:\", predicted_class.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "x6dJexUSzDhI",
    "nbgrader": {
     "checksum": "7126e6798f657baa53e1d4e360614e02",
     "grade": false,
     "grade_id": "cell-b1f2a02a37c3f405",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "__Answer the following question (enter the answer in the box below each one):__\n",
    "\n",
    "__1.__ How many images were missclassified? Which images?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "id": "XKm11pz1zDhJ",
    "nbgrader": {
     "checksum": "2bfced6d006c0b957ba58544a03b12f2",
     "grade": true,
     "grade_id": "cell-092c153f41f2dd1d",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "Just one image was misclassified (actual class 6, predicted class 5)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "5_2_Loading.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/ecs-vlc/COMP6248/blob/master/docs/labs/lab5/5_2_Loading.ipynb",
     "timestamp": 1583933599223
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
